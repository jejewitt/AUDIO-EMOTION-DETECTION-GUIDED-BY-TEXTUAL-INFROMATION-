{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2DCNN RAVDESS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jXyylTCOdbC"
      },
      "source": [
        "%%capture\n",
        "!pip install np_utils\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuO0jqHs_ifI"
      },
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "from sklearn.model_selection import train_test_split,KFold,StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder,normalize\n",
        "import pickle\n",
        "\n",
        "import keras\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import  MaxPool2D,Dense,Input,Convolution2D,Flatten,Activation,Dropout\n",
        "from keras import models,optimizers,losses\n",
        "from keras.utils import np_utils\n",
        "\n",
        "\n",
        "from keras.activations import softmax, relu \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBLHdQsX_0iW",
        "outputId": "5bc1acb2-2aa0-4410-b36e-267aa6f5655c"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"./drive/MyDrive/Project/\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJxB4ES7_0kx"
      },
      "source": [
        "lab = ['01_neutral','02_calm','03_happy','04_sad','05_angry','06_fearful','07_disgust','08_surprised']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeSbSte__0ni"
      },
      "source": [
        "def convert_mfcc(path, bands, sample,duration):\n",
        "    mf = np.empty(shape=(len(path), bands, 282, 1))\n",
        "    total_len = sample*duration\n",
        "    for i,one_path in enumerate(path):\n",
        "        data,sr = librosa.load(one_path,sr=sample,res_type=\"kaiser_fast\",duration=duration,offset=0.8) # offeset is the start\n",
        "        data_len = len(data)\n",
        "        if data_len > total_len:\n",
        "            offset = np.random.randint((data_len - total_len))\n",
        "            data = data[offset:(total_len+offset)]\n",
        "        elif total_len > data_len:\n",
        "            offset = np.random.randint(( total_len-data_len))\n",
        "            data = np.pad(data, (offset, int(total_len) - len(data) - offset), \"constant\")\n",
        "        else:\n",
        "            data = np.pad(data, (0, int(total_len) - len(data)), \"constant\")\n",
        "        mf[i,] = np.expand_dims(librosa.feature.mfcc(data, sr=sample, n_mfcc=bands), axis=-1)\n",
        "    return mf\n",
        "def get_model(bands):\n",
        "    input = Input(shape=(bands,282,1))\n",
        "    X = Convolution2D(64, (10,30), padding=\"same\")(input)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    X = MaxPool2D()(X)\n",
        "    X = Dropout(rate=0.2)(X)\n",
        "    \n",
        "    X = Convolution2D(64, (10,30), padding=\"same\")(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    X = MaxPool2D()(X)\n",
        "    X = Dropout(rate=0.2)(X)\n",
        "\n",
        "    \n",
        "    X = Convolution2D(64, (10,30), padding=\"same\")(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    X = MaxPool2D()(X)\n",
        "    X = Dropout(rate=0.75)(X)\n",
        "\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(64)(X)\n",
        "    X = Dropout(rate=0.2)(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    X = Dropout(rate=0.2)(X)\n",
        "    \n",
        "    out = Dense(8, activation=softmax)(X)\n",
        "    model = models.Model(inputs=input, outputs=out)\n",
        "    model.compile(optimizer=optimizers.Adam(0.001), loss=losses.categorical_crossentropy, metrics=['acc'])\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iME2Et9G_0p5"
      },
      "source": [
        "wav_list = []\n",
        "labels = []\n",
        "for i in range(1,25):\n",
        "    da= os.listdir(f\"Data/Actor_%02d\"% (i,))\n",
        "    # print(da[0])\n",
        "    \n",
        "    for k in da:\n",
        "        if '.wav' in k:\n",
        "            labels.append(k[6:8])\n",
        "            wav_list.append(f\"./Data/Actor_%02d/\"% (i,) + k) \n",
        "            # break\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE-bOwcHJI74"
      },
      "source": [
        "sample=48000\n",
        "duration=3\n",
        "bands = 30\n",
        "mfcc = convert_mfcc(wav_list, bands,sample,duration)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFM4Nwt8WIjR"
      },
      "source": [
        "# with open('mfcc_rav_1.pkl', 'wb') as handle:\n",
        "#     pickle.dump(mfcc, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "# with open('label_rav_1.pkl', 'wb') as handle:\n",
        "#     pickle.dump(labels, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epmJKxWhWTJg"
      },
      "source": [
        "mfcc = []\n",
        "with open('mfcc_rav_1.pkl', 'rb') as handle:\n",
        "    mfcc = pickle.load(handle)\n",
        "label = []\n",
        "with open('label_rav_1.pkl', 'rb') as handle:\n",
        "    labels = pickle.load(handle)\n",
        "n_mfcc = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxViy4csMt2D"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(mfcc\n",
        "                                                    , labels\n",
        "                                                    , test_size=0.2\n",
        "                                                    , shuffle=True\n",
        "                                                    , random_state=42\n",
        "                                                    ,stratify=labels\n",
        "                                                   )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRsP1IdONDHd"
      },
      "source": [
        "\n",
        "\n",
        "lb = LabelEncoder()\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtN-ySnFNFwp"
      },
      "source": [
        "\n",
        "\n",
        "mean = np.mean(X_train, axis=0)\n",
        "std = np.std(X_train, axis=0)\n",
        "\n",
        "X_train = (X_train - mean)/std\n",
        "X_test = (X_test - mean)/std\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='e.h5', \n",
        "                             monitor='val_acc',\n",
        "                             verbose=1, \n",
        "                             save_best_only=True,\n",
        "                             mode='max')\n",
        "\n",
        "model = get_model(bands)\n",
        "model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
        "                    batch_size=64, verbose = 2, epochs=400,callbacks=[checkpoint])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L512rnSCOpRg"
      },
      "source": [
        "# model.load_weights('e.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfAGeuoYOpZg"
      },
      "source": [
        "%%capture cap --no-stderr\n",
        "# KF = KFold(n_splits=5, random_state=42, shuffle=True)\n",
        "KF = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "for train_index, test_index in KF.split(mfcc,labels):\n",
        "    checkpoint = ModelCheckpoint(filepath='e.h5', \n",
        "                             monitor='val_acc',\n",
        "                             verbose=1, \n",
        "                             save_best_only=True,\n",
        "                             mode='max')\n",
        "    X_train, X_test = mfcc[train_index], mfcc[test_index]\n",
        "    y_train, y_test = np.asarray(labels)[train_index], np.asarray(labels)[test_index]\n",
        "\n",
        "    lb = LabelEncoder()\n",
        "    y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "    y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
        "\n",
        "    mean = np.mean(X_train, axis=0)\n",
        "    std = np.std(X_train, axis=0)\n",
        "\n",
        "    X_train = (X_train - mean)/std\n",
        "    X_test = (X_test - mean)/std\n",
        "\n",
        "    model = get_model(bands)\n",
        "    model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
        "                        batch_size=64, verbose = 2, epochs=400,callbacks=[checkpoint]) \n",
        "    \n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iQkZKH_OpcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85c5955a-d83f-4108-9c84-9df2b9f38d0b"
      },
      "source": [
        "cap"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.utils.capture.CapturedIO at 0x7f32d3607d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9VxRjY7OpeU"
      },
      "source": [
        "with open('output.txt', 'w') as f:\n",
        "    f.write(cap.stdout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eASJdBn1gR0n"
      },
      "source": [
        "# model.load_weights('e.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}